{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv1D, Dense, Dropout, Activation, Embedding, GlobalMaxPool1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "embedding_size = 100\n",
    "dropout=0.5\n",
    "epochs = 10\n",
    "validation_split = 0.1\n",
    "batch_size = 128\n",
    "filters= 200 \n",
    "kernel_size= 3\n",
    "num_words = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = Word2Vec.load('./word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878856"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq = tokenizer.texts_to_sequences(train.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(train_seq, maxlen=max_len, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(train.Lable).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_class = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embedding_size), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_count = 0\n",
    "unknown_freq = {}\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index >= vocab_size: \n",
    "            continue\n",
    "    try:\n",
    "        embedding_matrix[index, :] = word_vec.wv[word]\n",
    "    except KeyError:\n",
    "        unknown_freq[word] = tokenizer.word_counts[word]\n",
    "        unknown_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computation_graph():\n",
    "    model  = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, weights=[embedding_matrix], name='Embedding_Layer'))\n",
    "    model.add(Conv1D(filters= filters, \n",
    "                     kernel_size= kernel_size,\n",
    "                     activation = 'relu',\n",
    "                     name= '_'.join(['Convolution_1D', str(filters), str(kernel_size)])))\n",
    "    model.add(GlobalMaxPool1D(name='Global_Max_Pooling'))\n",
    "    model.add(Dense(units=filters, name='Dense_'+str(filters)))\n",
    "    model.add(Dropout(rate=dropout, name = 'Dropout_' + str(dropout)))\n",
    "    model.add(Activation('relu', name='Activation_'+str('relu')))\n",
    "    model.add(Dense(units=n_class, activation='softmax', name='Dense_'+str(n_class)+'_Sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = computation_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Embedding_Layer (Embedding)  (None, None, 100)         87885600  \n",
      "_________________________________________________________________\n",
      "Convolution_1D_200_3 (Conv1D (None, None, 200)         60200     \n",
      "_________________________________________________________________\n",
      "Global_Max_Pooling (GlobalMa (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_200 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "Dropout_0.5 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Activation_relu (Activation) (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_14_Sigmoid (Dense)     (None, 14)                2814      \n",
      "=================================================================\n",
      "Total params: 87,988,814\n",
      "Trainable params: 87,988,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 34s 760us/step - loss: 0.9637 - acc: 0.7016 - val_loss: 0.5476 - val_acc: 0.8272\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 31s 696us/step - loss: 0.7193 - acc: 0.7729 - val_loss: 2.1145 - val_acc: 0.3092\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 34s 759us/step - loss: 1.9882 - acc: 0.3032 - val_loss: 1.9579 - val_acc: 0.3092\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 32s 710us/step - loss: 1.9776 - acc: 0.3038 - val_loss: 1.9576 - val_acc: 0.3092\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 32s 711us/step - loss: 1.9749 - acc: 0.3038 - val_loss: 1.9572 - val_acc: 0.3092\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 33s 743us/step - loss: 1.9737 - acc: 0.3038 - val_loss: 1.9572 - val_acc: 0.3092\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 33s 726us/step - loss: 1.9723 - acc: 0.3038 - val_loss: 1.9573 - val_acc: 0.3092\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 32s 719us/step - loss: 1.9722 - acc: 0.3038 - val_loss: 1.9570 - val_acc: 0.3092\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 33s 726us/step - loss: 1.9703 - acc: 0.3038 - val_loss: 1.9575 - val_acc: 0.3092\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 33s 730us/step - loss: 1.9710 - acc: 0.3038 - val_loss: 1.9571 - val_acc: 0.3092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train,\n",
    "                          validation_split = validation_split,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
